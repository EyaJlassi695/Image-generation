{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training layer 1\n",
      "epoch 0/200 - loss : 0.018832015705162058\n",
      "epoch 10/200 - loss : 0.008511363451050429\n",
      "epoch 20/200 - loss : 0.00681772288316288\n",
      "epoch 30/200 - loss : 0.006006971625070392\n",
      "epoch 40/200 - loss : 0.005493338220983507\n",
      "epoch 50/200 - loss : 0.005146661293993352\n",
      "epoch 60/200 - loss : 0.004867468401206491\n",
      "epoch 70/200 - loss : 0.004670276806067384\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 77\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;66;03m# Initialize and train DBN\u001b[39;00m\n\u001b[0;32m     76\u001b[0m dbn \u001b[38;5;241m=\u001b[39m DBN(layer_sizes)\n\u001b[1;32m---> 77\u001b[0m \u001b[43mdbn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_DBN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs_per_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\n\u001b[0;32m     78\u001b[0m \u001b[43m              \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Generate and visualize images\u001b[39;00m\n\u001b[0;32m     81\u001b[0m images\u001b[38;5;241m=\u001b[39m dbn\u001b[38;5;241m.\u001b[39mgenerer_image_DBN(nb_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, gibbs_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 26\u001b[0m, in \u001b[0;36mDBN.train_DBN\u001b[1;34m(self, training_set, learning_rate, batch_size, n_epochs_per_layer, verbose)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_RBM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs_per_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     training_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[i]\u001b[38;5;241m.\u001b[39mentree_sortie_RBM(training_set)\n",
      "File \u001b[1;32mc:\\env\\DL2\\models.py:50\u001b[0m, in \u001b[0;36mRBM.train_RBM\u001b[1;34m(self, training_set, learning_rate, batch_size, n_epochs, verbose)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ma \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m da\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m db\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m learning_rate \u001b[38;5;241m*\u001b[39m dW\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Reconstruction error\u001b[39;00m\n\u001b[0;32m     54\u001b[0m H \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentree_sortie_RBM(training_set)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "from utils import *\n",
    "from models import RBM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from diffusers import DDPMPipeline, DDPMScheduler, UNet2DModel\n",
    "from models import DNN, RBM,DBN\n",
    "\n",
    "class DBN:\n",
    "    def __init__(self, layer_sizes):\n",
    "        self.L = len(layer_sizes) - 1  # number of hidden layers\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.layers = [RBM(layer_sizes[i], layer_sizes[i+1]) for i in range(len(layer_sizes)-1)]\n",
    "\n",
    "    def train_DBN(self, training_set, learning_rate, batch_size, n_epochs_per_layer, verbose=False):\n",
    "        for i in range(self.L):\n",
    "            print(f'Training layer {i+1}')\n",
    "            self.layers[i].train_RBM(training_set, learning_rate, batch_size, n_epochs_per_layer, verbose)\n",
    "            training_set = self.layers[i].entree_sortie_RBM(training_set)\n",
    "\n",
    "    def generer_image_DBN(self, nb_images, gibbs_steps, size_img=(28, 28)):\n",
    "        p = self.layers[0].W.shape[0]  # Input layer size\n",
    "        images = []\n",
    "        for _ in range(nb_images):\n",
    "            # Initialize a random visible vector\n",
    "            v = (np.random.rand(1, p) < 0.5).astype(np.float32)  # Ensure (1, p) shape\n",
    "            \n",
    "            for _ in range(gibbs_steps):\n",
    "                # Propagate upwards through the DBN (visible → hidden)\n",
    "                for rbm in self.layers:\n",
    "                    v = rbm.entree_sortie_RBM(v)  # Hidden activation\n",
    "                    v = (np.random.rand(*v.shape) < v).astype(np.float32)  # Sample binary hidden state\n",
    "\n",
    "                # Propagate downwards through the DBN (hidden → visible)\n",
    "                for rbm in reversed(self.layers):\n",
    "                    v = rbm.sortie_entree_RBM(v)  # Visible activation\n",
    "                    v = (np.random.rand(*v.shape) < v).astype(np.float32)  # Sample binary visible state\n",
    "            \n",
    "            # Reshape the final visible layer back to an image\n",
    "            images.append(v.reshape(size_img))\n",
    "        return images\n",
    "def lire_mnist_all():\n",
    "    \"\"\"\n",
    "    Read all the data from the MNIST dataset.\n",
    "\n",
    "    Returns:\n",
    "    X_train, y_train: Training data and labels (flattened images)\n",
    "    X_test, y_test: Test data and labels (flattened images)\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # Flatten images\n",
    "    X_train = X_train.reshape(-1, 28*28)\n",
    "    X_test = X_test.reshape(-1, 28*28)\n",
    "\n",
    "    # Binarize\n",
    "    X_train = (X_train > 127).astype(int)\n",
    "    X_test = (X_test > 127).astype(int)\n",
    "\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = lire_mnist_all()\n",
    "dim_visible = X_train.shape[1]  # Infer p from X\n",
    "layer_sizes = [dim_visible, 500, 250, 100]  # Example structure\n",
    "\n",
    "# Initialize and train DBN\n",
    "dbn = DBN(layer_sizes)\n",
    "dbn.train_DBN(X_train, learning_rate=0.01, batch_size=10, n_epochs_per_layer=200\n",
    "              , verbose=True)\n",
    "\n",
    "# Generate and visualize images\n",
    "images= dbn.generer_image_DBN(nb_images=16, gibbs_steps=200)\n",
    "plot_generated_images(images, image_shape=(28, 28))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
